import os
import subprocess
import platform
import pandas as pd
from transformers import pipeline
from edgar import Company, set_identity 
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ===================================================================
# 1. ì‹ ì› ì„¤ì •
# ===================================================================
set_identity("Seungtae Kim st45783@skku.edu")

# ===================================================================
# 2. GPU ì„ íƒ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# ===================================================================
def select_device():
    # Mac M1/Vë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ ì²´í¬
    if platform.system() == 'Darwin' and 'arm' in platform.machine().lower():
        print("Mac M1 í™˜ê²½ ê°ì§€: MPS ì‚¬ìš©")
        return 'mps'
    else:
        # ê¸°ì¡´ GPU ì„ íƒ í•¨ìˆ˜ í˜¸ì¶œ ë˜ëŠ” ë””í´íŠ¸ GPU ë°˜í™˜
        try:
            gpu_info_cmd = "nvidia-smi --query-gpu=index,uuid --format=csv,noheader,nounits"
            result = subprocess.run(gpu_info_cmd.split(), capture_output=True, text=True, check=True)
            index_to_uuid = {int(index): uuid.strip() for index, uuid in (line.split(', ') for line in result.stdout.strip().split('\n') if line)}
            busy_apps_cmd = "nvidia-smi --query-compute-apps=gpu_uuid --format=csv,noheader,nounits"
            result = subprocess.run(busy_apps_cmd.split(), capture_output=True, text=True, check=True)
            busy_uuids = {line.strip() for line in result.stdout.strip().split('\n') if line}
            for index, uuid in index_to_uuid.items():
                if uuid not in busy_uuids:
                    print(f"âœ… ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ê°€ ì—†ëŠ” GPU {index}ë²ˆì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
                    return str(index)
            return "0"
        except Exception:
            print("âœ… GPU ìƒíƒœ í™•ì¸ ë¶ˆê°€. 0ë²ˆ GPUë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.")
            return "0"

# ===================================================================
# 3. MD&A ì¶”ì¶œ í•¨ìˆ˜ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# ===================================================================
def get_10q_mda_text(ticker):
    try:
        print(f"ğŸ“‹ {ticker}ì˜ ìµœê·¼ 10-Q ë³´ê³ ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘...")
        company = Company(ticker)
        filing_10q = company.get_filings(form="10-Q").latest()
        if filing_10q is None:
            print(f"â—ï¸ {ticker}ì˜ 10-Q ë³´ê³ ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        print(f"âœ… {filing_10q.form} ë³´ê³ ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤ (ì œì¶œì¼: {filing_10q.filing_date})")
        print("ğŸ“„ MD&A ì„¹ì…˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì¤‘...")
        tenq_obj = filing_10q.obj()
        mda_text = tenq_obj['Item 2']
        if not mda_text:
             print(f"â—ï¸ í•´ë‹¹ ë³´ê³ ì„œì—ì„œ MD&A ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
             return None
        print(f"âœ… MD&A í…ìŠ¤íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤ (ì´ {len(mda_text):,}ì)")
        return mda_text
    except Exception as e:
        print(f"â—ï¸ 10-Q ë³´ê³ ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

# ===================================================================
# ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ===================================================================
device_choice = select_device()
if device_choice == 'mps':
    os.environ["DEVICE_TYPE"] = "mps"
else:
    os.environ["CUDA_VISIBLE_DEVICES"] = device_choice

print("ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
sentiment_analyzer = pipeline("text-classification", model="ProsusAI/finbert", device=0)
print("âœ… ëª¨ë¸ ë¡œë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

target_tickers = ["ABBV", "ACIC", "APP", "ASM", "CLS", "FTAI", "HCA", "HRTG", "IAG", "LMB", "MAMA", "MFH", "PLTR", "POWL", "PSIX", "SLNO", "SMMT", "STRL", "TSSI", "UAMY", "VRNA", "MONEY"]
  # ì—¬ëŸ¬ í‹°ì»¤ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì§€ì •
# target_ticker = "psix"  # ê¸°ì¡´ ë‹¨ì¼ í‹°ì»¤ ì£¼ì„ ì²˜ë¦¬

# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
analysis_results = []

# ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
analysis_results = []

# ì—¬ëŸ¬ í‹°ì»¤ì— ëŒ€í•´ ë°˜ë³µ ì²˜ë¦¬
for ticker in target_tickers:
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {ticker.upper()} ë¶„ì„ ì‹œì‘")
    print(f"{'='*60}")
    
    mda_full_text = get_10q_mda_text(ticker)

    if not mda_full_text:
        print(f"âš ï¸  {ticker.upper()}ì˜ MD&A í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•´ í•´ë‹¹ í‹°ì»¤ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ê²°ê³¼ì— ì¶”ê°€ (None ê°’ìœ¼ë¡œ)
        analysis_results.append({
            'ticker': ticker.upper(),
            'positive': None,
            'neutral': None,
            'negative': None,
            'polarity_score': None,
            'filtered_positive': None,
            'filtered_neutral': None,
            'filtered_negative': None
        })
        continue

    print("\nâš™ï¸  ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„ ê°€ëŠ¥í•œ ì¡°ê°ìœ¼ë¡œ ë¶„í• í•˜ëŠ” ì¤‘...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, length_function=len)
    text_chunks = text_splitter.split_text(mda_full_text)
    print(f"âœ… í…ìŠ¤íŠ¸ê°€ ì´ {len(text_chunks)}ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")

    print(f"\nğŸ”¬ {len(text_chunks)}ê°œì˜ ëª¨ë“  ì¡°ê°ì— ëŒ€í•œ ê°ì„± ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    results = sentiment_analyzer(text_chunks, top_k=None)
    print("âœ… ëª¨ë“  ì¡°ê° ë¶„ì„ ì™„ë£Œ!")

    # --- (ê¸°ì¡´ ê²°ê³¼ ì¢…í•© ë¡œì§) ---
    total_scores = {'positive': 0.0, 'negative': 0.0, 'neutral': 0.0}
    total_chunks = len(text_chunks)
    if total_chunks == 0:
        print(f"â—ï¸ {ticker.upper()}ì˜ ë¶„ì„í•  í…ìŠ¤íŠ¸ ì¡°ê°ì´ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ í‹°ì»¤ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        analysis_results.append({
            'ticker': ticker.upper(),
            'positive': None,
            'neutral': None,
            'negative': None,
            'polarity_score': None,
            'filtered_positive': None,
            'filtered_neutral': None,
            'filtered_negative': None
        })
        continue

    for chunk_result in results:
        for score_info in chunk_result:
            label = score_info['label'].lower()
            score = score_info['score']
            if label in total_scores:
                total_scores[label] += score

    average_scores = {label: score / total_chunks for label, score in total_scores.items()}

    print(f"\n--- [{ticker.upper()} 10-Q MD&A] ì „ì²´ í…ìŠ¤íŠ¸ í‰ê·  ê°ì„± ì ìˆ˜ ---")
    print(f"ğŸ“Š ì „ì²´ {total_chunks}ê°œ ì¡°ê° ê¸°ì¤€:")
    print(f"  - ê¸ì • (Positive) ğŸŸ¢: {average_scores['positive']:.4f} ({average_scores['positive']*100:.1f}%)")
    print(f"  - ë¶€ì • (Negative) ğŸ”´: {average_scores['negative']:.4f} ({average_scores['negative']*100:.1f}%)")
    print(f"  - ì¤‘ë¦½ (Neutral)  âšªï¸: {average_scores['neutral']:.4f} ({average_scores['neutral']*100:.1f}%)")

    # ===================================================================
    # â­ ê°ì„± ì‹ í˜¸ ë¶€ê°ì„ ìœ„í•œ ì¶”ê°€ ë¶„ì„
    # ===================================================================

    print(f"\n--- ê°ì„± ì‹ í˜¸ ë¶€ê° ë¶„ì„ ê²°ê³¼ ---")

    # --- ë°©ë²• 1: ì¤‘ë¦½ì„ ì œì™¸í•œ ê°ì„± ì–‘ê·¹ì„±(Polarity) ì ìˆ˜ ê³„ì‚° ---
    pos_score = average_scores['positive']
    neg_score = average_scores['negative']
    polarity_score = pos_score / (pos_score + neg_score) if (pos_score + neg_score) > 0 else 0
    print(f"ğŸ“ˆ ê°ì„± ì–‘ê·¹ì„±(Polarity) ì ìˆ˜: {polarity_score:.4f}")
    print(f"   (í•´ì„: ì¤‘ë¦½ì„ ì œì™¸í•œ ê°ì„± ì¤‘ ê¸ì •ì´ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì´ {polarity_score*100:.1f}%ì„ì„ ì˜ë¯¸)")

    # --- ë°©ë²• 2: ê°ì„± ì¡°ê° í•„í„°ë§ í›„ í‰ê·  ì¬ê³„ì‚° ---
    sentimental_scores = {'positive': 0.0, 'negative': 0.0, 'neutral': 0.0}
    sentimental_chunk_count = 0
    for chunk_result in results:
        # ê° ì¡°ê°ì—ì„œ ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ë ˆì´ë¸”ì„ ì°¾ìŒ
        dominant_sentiment = max(chunk_result, key=lambda x: x['score'])
        
        # ì§€ë°°ì ì¸ ê°ì„±ì´ 'ì¤‘ë¦½'ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì§‘ê³„
        if dominant_sentiment['label'].lower() != 'neutral':
            sentimental_chunk_count += 1
            for score_info in chunk_result:
                label = score_info['label'].lower()
                sentimental_scores[label] += score_info['score']

    if sentimental_chunk_count > 0:
        filtered_average_scores = {
            label: score / sentimental_chunk_count for label, score in sentimental_scores.items()
        }
        print(f"\nğŸ“Š ì¤‘ë¦½ ì œì™¸ {sentimental_chunk_count}ê°œ ì¡°ê° ê¸°ì¤€ í‰ê·  ê°ì„±:")
        print(f"  - ê¸ì • (Positive) ğŸŸ¢: {filtered_average_scores['positive']:.4f} ({filtered_average_scores['positive']*100:.1f}%)")
        print(f"  - ë¶€ì • (Negative) ğŸ”´: {filtered_average_scores['negative']:.4f} ({filtered_average_scores['negative']*100:.1f}%)")
        print(f"  - ì¤‘ë¦½ (Neutral)  âšªï¸: {filtered_average_scores['neutral']:.4f} ({filtered_average_scores['neutral']*100:.1f}%)")
    else:
        print("\nğŸ“Š ì¤‘ë¦½ì„ ì œì™¸í•œ ê°ì„±ì ì¸ ì¡°ê°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        filtered_average_scores = {'positive': None, 'negative': None, 'neutral': None}

    # ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    analysis_results.append({
        'ticker': ticker.upper(),
        'positive': average_scores['positive'],
        'neutral': average_scores['neutral'], 
        'negative': average_scores['negative'],
        'polarity_score': polarity_score,
        'filtered_positive': filtered_average_scores['positive'],
        'filtered_neutral': filtered_average_scores['neutral'],
        'filtered_negative': filtered_average_scores['negative']
    })

print("\n" + "="*60)
print("ğŸ¯ ëª¨ë“  í‹°ì»¤ ë¶„ì„ ì™„ë£Œ!")
print("="*60)

# ===================================================================
# CSV íŒŒì¼ë¡œ ê²°ê³¼ ì €ì¥
# ===================================================================
print("\nğŸ“Š ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")

# DataFrame ìƒì„±
df = pd.DataFrame(analysis_results)

# ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©ìê°€ ìš”ì²­í•œ í˜•íƒœë¡œ ë³€ê²½
df.columns = [
    'Ticker',
    'Positive',
    'Neutral', 
    'Negative',
    'Polarity_Score',
    'Filtered_Positive',
    'Filtered_Neutral',
    'Filtered_Negative'
]

# CSV íŒŒì¼ëª… ìƒì„± (í˜„ì¬ ë‚ ì§œ í¬í•¨)
from datetime import datetime
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
csv_filename = f"finbert_sentiment_analysis_{timestamp}.csv"

# CSV íŒŒì¼ ì €ì¥
df.to_csv(csv_filename, index=False, float_format='%.4f')

print(f"âœ… ë¶„ì„ ê²°ê³¼ê°€ '{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("\nğŸ“‹ ê²°ê³¼ ìš”ì•½:")
print(df.to_string(index=False, float_format='%.4f'))

print("\nğŸ“– ì»¬ëŸ¼ ì„¤ëª…:")
print("  - Ticker: ì¢…ëª© í‹°ì»¤")
print("  - Positive: ê¸ì • ê°ì„± í‰ê·  ì ìˆ˜")
print("  - Neutral: ì¤‘ë¦½ ê°ì„± í‰ê·  ì ìˆ˜") 
print("  - Negative: ë¶€ì • ê°ì„± í‰ê·  ì ìˆ˜")
print("  - Polarity_Score: ê°ì„± ì–‘ê·¹ì„± ì ìˆ˜ (ê¸ì •/(ê¸ì •+ë¶€ì •))")
print("  - Filtered_Positive: ì¤‘ë¦½ ì œì™¸í•œ ê¸ì • ê°ì„± ì ìˆ˜")
print("  - Filtered_Neutral: ì¤‘ë¦½ ì œì™¸í•œ ì¤‘ë¦½ ê°ì„± ì ìˆ˜")
print("  - Filtered_Negative: ì¤‘ë¦½ ì œì™¸í•œ ë¶€ì • ê°ì„± ì ìˆ˜")

print("----------------------------------------------------------")

# ===================================================================
# â­ ì‹ í˜¸ ë¶€ê°ì„ ìœ„í•œ ì¶”ê°€ ë¶„ì„ (ì´ ë¶€ë¶„ì„ ì¶”ê°€)
# ===================================================================

print(f"\n--- ê°ì„± ì‹ í˜¸ ë¶€ê° ë¶„ì„ ê²°ê³¼ ---")

# --- ë°©ë²• 1: ì¤‘ë¦½ì„ ì œì™¸í•œ ê°ì„± ì–‘ê·¹ì„±(Polarity) ì ìˆ˜ ê³„ì‚° ---
pos_score = average_scores['positive']
neg_score = average_scores['negative']
polarity_score = pos_score / (pos_score + neg_score) if (pos_score + neg_score) > 0 else 0
print(f"ğŸ“ˆ ê°ì„± ì–‘ê·¹ì„±(Polarity) ì ìˆ˜: {polarity_score:.4f}")
print(f"   (í•´ì„: ì¤‘ë¦½ì„ ì œì™¸í•œ ê°ì„± ì¤‘ ê¸ì •ì´ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ì´ {polarity_score*100:.1f}%ì„ì„ ì˜ë¯¸)")

# --- ë°©ë²• 2: ê°ì„± ì¡°ê° í•„í„°ë§ í›„ í‰ê·  ì¬ê³„ì‚° ---
sentimental_scores = {'positive': 0.0, 'negative': 0.0, 'neutral': 0.0}
sentimental_chunk_count = 0
for chunk_result in results:
    # ê° ì¡°ê°ì—ì„œ ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ë ˆì´ë¸”ì„ ì°¾ìŒ
    dominant_sentiment = max(chunk_result, key=lambda x: x['score'])
    
    # ì§€ë°°ì ì¸ ê°ì„±ì´ 'ì¤‘ë¦½'ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì§‘ê³„
    if dominant_sentiment['label'].lower() != 'neutral':
        sentimental_chunk_count += 1
        for score_info in chunk_result:
            label = score_info['label'].lower()
            sentimental_scores[label] += score_info['score']

if sentimental_chunk_count > 0:
    filtered_average_scores = {
        label: score / sentimental_chunk_count for label, score in sentimental_scores.items()
    }
    print(f"\nğŸ“Š ì¤‘ë¦½ ì œì™¸ {sentimental_chunk_count}ê°œ ì¡°ê° ê¸°ì¤€ í‰ê·  ê°ì„±:")
    print(f"  - ê¸ì • (Positive) ğŸŸ¢: {filtered_average_scores['positive']:.4f} ({filtered_average_scores['positive']*100:.1f}%)")
    print(f"  - ë¶€ì • (Negative) ğŸ”´: {filtered_average_scores['negative']:.4f} ({filtered_average_scores['negative']*100:.1f}%)")
    print(f"  - ì¤‘ë¦½ (Neutral)  âšªï¸: {filtered_average_scores['neutral']:.4f} ({filtered_average_scores['neutral']*100:.1f}%)")
else:
    print("\nğŸ“Š ì¤‘ë¦½ì„ ì œì™¸í•œ ê°ì„±ì ì¸ ì¡°ê°ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

print("----------------------------------------------------------")

